{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets.core' has no attribute 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Reham Essa\\Desktop\\iti winter\\day9\\lec9.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Reham%20Essa/Desktop/iti%20winter/day9/lec9.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Reham%20Essa/Desktop/iti%20winter/day9/lec9.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Reham%20Essa/Desktop/iti%20winter/day9/lec9.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\__init__.py:47\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/__init__.py?line=43'>44</a>\u001b[0m tf_compat\u001b[39m.\u001b[39mensure_tf_install()\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/__init__.py?line=45'>46</a>\u001b[0m \u001b[39m# Imports for registration\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/__init__.py?line=46'>47</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m audio\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/__init__.py?line=47'>48</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m graphs\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\audio\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=13'>14</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=15'>16</a>\u001b[0m \u001b[39m\"\"\"Audio datasets.\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccentdb\u001b[39;00m \u001b[39mimport\u001b[39;00m Accentdb\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommonvoice\u001b[39;00m \u001b[39mimport\u001b[39;00m CommonVoice\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/__init__.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommonvoice\u001b[39;00m \u001b[39mimport\u001b[39;00m CommonVoiceConfig\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\audio\\accentdb.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=17'>18</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=19'>20</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpublic_api\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=21'>22</a>\u001b[0m _CITATION \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=22'>23</a>\u001b[0m \u001b[39m@InProceedings\u001b[39m\u001b[39m{\u001b[39m\u001b[39mahamad-anand-bhargava:2020:LREC,\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=23'>24</a>\u001b[0m \u001b[39m  author    = \u001b[39m\u001b[39m{\u001b[39m\u001b[39mAhamad, Afroz  and  Anand, Ankit  and  Bhargava, Pranesh},\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=31'>32</a>\u001b[0m \u001b[39m  url       = \u001b[39m\u001b[39m{\u001b[39m\u001b[39mhttps://www.aclweb.org/anthology/2020.lrec-1.659}\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=32'>33</a>\u001b[0m \u001b[39m}\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=34'>35</a>\u001b[0m _DESCRIPTION \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=35'>36</a>\u001b[0m \u001b[39mAccentDB is a multi-pairwise parallel corpus of structured and labelled\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=36'>37</a>\u001b[0m \u001b[39maccented speech. It contains speech samples from speakers of 4 non-native\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=40'>41</a>\u001b[0m \u001b[39mtitled accentdb_extended on https://accentdb.github.io/#dataset.\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/audio/accentdb.py?line=41'>42</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\public_api.py:54\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=50'>51</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization\u001b[39;00m \u001b[39mimport\u001b[39;00m show_statistics\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=51'>52</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=53'>54</a>\u001b[0m deprecated \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39mdocs\u001b[39m.\u001b[39mdeprecated(deprecated)\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=55'>56</a>\u001b[0m \u001b[39mwith\u001b[39;00m core\u001b[39m.\u001b[39mregistered\u001b[39m.\u001b[39mskip_registration():\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=56'>57</a>\u001b[0m   \u001b[39m# We import testing namespace but without registering the tests datasets\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=57'>58</a>\u001b[0m   \u001b[39m# (e.g. DummyMnist,...).\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow_datasets/public_api.py?line=58'>59</a>\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m testing\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_datasets.core' has no attribute 'utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Reham Essa\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:01,  1.68 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.68 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.68 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.88 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:00,  1.88 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:00,  1.88 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:04<00:00,  1.23s/ url]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:04<00:00,  1.23s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:05<00:00,  1.23s/ url]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:05<00:00,  1.39s/ file]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:05<00:00,  1.79 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:05<00:00,  1.40s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\Reham Essa\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='C:\\\\Users\\\\Reham Essa\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset,metadate=tfds.load(\"mnist\",as_supervised=True,with_info=True)\n",
    "metadate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset=dataset[\"train\"],dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type of image from int to float to minimize weight\n",
    "def normalize(images,labels):\n",
    "    images=tf.cast(images,tf.float32)\n",
    "    images /=255\n",
    "    return images,labels\n",
    "train_dataset=train_dataset.map(normalize)\n",
    "test_dataset=test_dataset.map(normalize)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image ,label in test_dataset.take(1):\n",
    "    break\n",
    "image=image.numpy().reshape((28,28))\n",
    "plt.figure()\n",
    "plt.imshow(image,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide Data into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train_dataset=train_dataset.cache().repeat().shuffle(60000).batch(BATCH_SIZE)\n",
    "tEST_dataset=test_dataset.cache().batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32,(3,3),padding=\"same\",activation=tf.nn.relu,input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPooling2D((2,2),strides=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation=tf.nn.relu,input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPooling2D((2,2),strides=2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10)\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 55s 28ms/step - loss: 0.1229 - accuracy: 0.9621\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0410 - accuracy: 0.9870\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0262 - accuracy: 0.9922\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0142 - accuracy: 0.9957\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(train_dataset,epochs=5,steps_per_epoch=math.ceil(60000/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_2_input'), name='conv2d_2_input', description=\"created by layer 'conv2d_2_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_2_input'), name='conv2d_2_input', description=\"created by layer 'conv2d_2_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"max_pooling2d_2\" (type MaxPooling2D).\n    \n    Negative dimension size caused by subtracting 2 from 1 for '{{node sequential/max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential/conv2d_2/Relu)' with input shapes: [28,28,1,32].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(28, 28, 1, 32), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Reham Essa\\Desktop\\iti winter\\day9\\lec9.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Reham%20Essa/Desktop/iti%20winter/day9/lec9.ipynb#ch0000021?line=0'>1</a>\u001b[0m test_loss,test_accuracy\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mevaluate(test_dataset, steps\u001b[39m=\u001b[39;49mmath\u001b[39m.\u001b[39;49mceil(\u001b[39m10000\u001b[39;49m\u001b[39m/\u001b[39;49mBATCH_SIZE))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\Reham Essa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"max_pooling2d_2\" (type MaxPooling2D).\n    \n    Negative dimension size caused by subtracting 2 from 1 for '{{node sequential/max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential/conv2d_2/Relu)' with input shapes: [28,28,1,32].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(28, 28, 1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_dataset, steps=math.ceil(10000/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.save of <keras.engine.sequential.Sequential object at 0x0000014964564220>>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707aab0a078b6b4ae7605615109a6f7159987081daedafbf3334295fb1ab1b6c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
