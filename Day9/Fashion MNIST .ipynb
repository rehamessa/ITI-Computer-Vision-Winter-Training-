{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, test_images = training_images.astype('float32'), test_images.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, test_images = training_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(60000,28,28,1)\n",
    "test_images = test_images.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = training_images[50000:]\n",
    "val_labels = training_labels[50000:]\n",
    "\n",
    "training_images = training_images[:50000]\n",
    "training_labels = training_labels[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1563/1563 - 38s - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.2843 - val_accuracy: 0.9167 - 38s/epoch - 24ms/step\n",
      "Epoch 2/8\n",
      "1563/1563 - 38s - loss: 0.0885 - accuracy: 0.9657 - val_loss: 0.3155 - val_accuracy: 0.9101 - 38s/epoch - 24ms/step\n",
      "Epoch 3/8\n",
      "1563/1563 - 39s - loss: 0.0783 - accuracy: 0.9700 - val_loss: 0.3294 - val_accuracy: 0.9128 - 39s/epoch - 25ms/step\n",
      "Epoch 4/8\n",
      "1563/1563 - 38s - loss: 0.0687 - accuracy: 0.9741 - val_loss: 0.3237 - val_accuracy: 0.9163 - 38s/epoch - 24ms/step\n",
      "Epoch 5/8\n",
      "1563/1563 - 37s - loss: 0.0597 - accuracy: 0.9775 - val_loss: 0.3490 - val_accuracy: 0.9128 - 37s/epoch - 24ms/step\n",
      "Epoch 6/8\n",
      "1563/1563 - 37s - loss: 0.0551 - accuracy: 0.9797 - val_loss: 0.4037 - val_accuracy: 0.9119 - 37s/epoch - 24ms/step\n",
      "Epoch 7/8\n",
      "1563/1563 - 37s - loss: 0.0470 - accuracy: 0.9824 - val_loss: 0.3893 - val_accuracy: 0.9104 - 37s/epoch - 24ms/step\n",
      "Epoch 8/8\n",
      "1563/1563 - 37s - loss: 0.0456 - accuracy: 0.9829 - val_loss: 0.4448 - val_accuracy: 0.9099 - 37s/epoch - 24ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels,\n",
    "                      validation_data = (val_images, val_labels),\n",
    "                      epochs = 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4694 - accuracy: 0.9055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4693865180015564, 0.9054999947547913]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707aab0a078b6b4ae7605615109a6f7159987081daedafbf3334295fb1ab1b6c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
